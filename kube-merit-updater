#!/bin/bash

# Shell style guide: https://google.github.io/styleguide/shell.xml

# ## (-)  master and worker steps
# ## (*)  worker specific steps
# ## (**) storage-node steps
#
# Assumes a kubernetes cluster with master and workers nodes and separate
# storage-nodes to schedule pvc related pods.
#
# - drain nodes (sequentially)
# - reboot nodes and wait until they are back and in `Ready` state
#
# For storage nodes we follow a different approach.
# Since all that it is running there are longhorn daemonsets and pvc replica controllers:
#
# ** Verify that all volumes have at least 1 replica on other storage-nodes
# ** reboot nodes and wait until they are back and in `Ready` state
# ** wait until longhorn mark them as Ready and Schedulable again

set -o errexit
set -o nounset
set -o pipefail

readonly retire_time=$(date +"%Y-%m-%dT%H-%M-%SZ")

# flags
kube_context=''
role=''
resume=''
timeout=600
socks5_proxy=''

# Static vars
storage_ns='sys-longhorn'
pvc_label_key='tier'
pvc_label_val='storage'
HTTP_PROXY=''

usage() {
  cat <<EOF
Usage: $0 -c <kube_context> -s [retire_time_label] -r [role]
        -t [timeout]

  -s    Resume node rolling. Argument is retire_time label. If set, -r [role]
        must also be set
  -t    Node drain timeout. How long to wait for the node to drain before
        shutting it down (in seconds, default 300s)
  -p    Specify a socks5 proxy for kubectl and lhctl commands <address>:<port>
EOF
}

while getopts 'c:r:h:s:t:p:' flag; do
  case "${flag}" in
    c) kube_context="${OPTARG}" ;;
    r) role="${OPTARG}" ;;
    s) resume="${OPTARG}" ;;
    t) timeout="${OPTARG}" ;;
    p) socks5_proxy="${OPTARG}" ;;
    h) usage && exit 0 ;;
    *) echo "Unexpected option: ${flag}" && usage && exit 1 ;;
  esac
done

### Deps
deps="
  awk
  jq
  kubectl
  lhctl
  ssh
  timeout
  uniq
  xargs
"

missing_deps=""
for d in ${deps}; do
  if ! command -v ${d} &> /dev/null; then
    missing_deps+="${d} "
  fi
done

if [[ -n "${missing_deps}" ]]; then
  echo "Missing dependencies: ${missing_deps}"
  exit 1
fi

## Set HTTP Proxy env var to proxy kubectl commands
if [[ -z "${socks5_proxy}" ]]; then
  echo "No socks proxy set"
else
  HTTP_PROXY="socks5://${socks5_proxy}"
fi
export HTTP_PROXY=${HTTP_PROXY}

### Validation
if [[ -z "${kube_context}" ]]; then
  usage
  exit 1
fi

if [[ -z "${role}" ]] ; then
  echo "A role should always be provided"
  usage
  exit 1
fi

function fail() {
  echo $1 >&2
  exit 1
}

function retry() {
  local n=1
  local max=12
  local delay=8
  while true; do
    "$@" && break || {
      if [[ $n -lt $max ]]; then
        ((n++))
        echo "command failed: attempt=$n max=$max"
        sleep $delay;
      else
        fail "the command has failed after $n attempts."
      fi
    }
  done
}

label_for_cycling() {
  local role=$1
  local nodes=""
  while [[ -z "${nodes}" ]]; do
    nodes=$(retry kubectl --context=${kube_context} get nodes -l role=${role} -o json | jq -r '.items[].metadata.name')
  done

  echo "${kube_context}: nodes=$(echo "${nodes}" | wc -l) role=${role}"
  echo "labelling for retirement: role=${role}"
  for node in ${nodes}; do
    retry kubectl --context=${kube_context} label node ${node} retiring=${retire_time} --overwrite=true
  done
}

delete_retirement_label() {
  local node=$1
  echo "removing labelling for retirement: role=${role}"
  retry kubectl --context=${kube_context} label node ${node} retiring-
}

label_storage_pods() {

  local storage_pods=$(retry kubectl --context=${kube_context} --namespace=${storage_ns} get po | grep instance-manager | awk '{print $1}' )

  for pod in ${storage_pods}; do
    echo "Labeling pod: ${pod} as ${pvc_label_key}=${pvc_label_val}"
    retry kubectl --context=${kube_context} --namespace=${storage_ns} label pod ${pod} ${pvc_label_key}=${pvc_label_val} --overwrite
  done
  echo "pods labelled"
}

delete_pods() {
  local node=$1

  retry kubectl --context=${kube_context} get pod --all-namespaces --selector="${pvc_label_key}!=${pvc_label_val}" \
    -o jsonpath='{range .items[?(.spec.nodeName=="'${node}'")]}{@.metadata.namespace} {.metadata.name} {end}' |\
    xargs -n2 |\
    xargs -I % sh -c "kubectl --context=${kube_context} delete pods -n=%"
}

drain_node() {
  local node=$1

  label_storage_pods # Label storage pods right before draining to catch any new storage pod creation

  set +e
  time timeout ${timeout} kubectl --context=${kube_context} drain ${node} --ignore-daemonsets --force --delete-local-data --pod-selector="${pvc_label_key}!=${pvc_label_val}"
  local rc=$?
  if [[ ${rc} -eq 0 ]]; then
    echo "drained successfully"
  elif [[ ${rc} -eq 124 ]]; then
    echo "timeout reached, continuing: timeout=${timeout}"
    delete_pods ${node}
  else
    echo "kubectl drain exit error: ${rc}"
    delete_pods ${node}
  fi
}

reboot_node() {
  local node=$1

  set +e

  ssh -o ServerAliveInterval=1 -o ServerAliveCountMax=1 -o BatchMode=yes ${node} sudo reboot

  local kube_active=$(ssh -oBatchMode=yes ${node} systemctl is-active kubelet.service)
  until [[ ${kube_active} == "active" ]]; do
    echo "awaiting node: ${node} to reboot and kubelet.service to become active"
    sleep 15
    kube_active=$(ssh -oBatchMode=yes ${node} systemctl is-active kubelet.service)
  done
}

wait_for_ready_node() {
  local node=$1

  set +e
  # Wait for node to report ready again
  local node_status=$(kubectl --context=${kube_context} get node | grep ${node} | awk '{print $2}')
  until [[ ${node_status} == "Ready,SchedulingDisabled" || ${node_status} == "Ready" ]]; do
    echo "awaiting node: ${node} to become Ready"
    sleep 10
    node_status=$(kubectl --context=${kube_context} get node | grep ${node} | awk '{print $2}')
  done
  # Uncordon the node
  retry kubectl --context=${kube_context} uncordon ${node}
}

check_node_volumes_are_detached() {

  echo "Verifying volumes detached before rebooting node ${node}"

  local node=$1
  local lh_external_ip=$2

  local volume_count=$(retry lhctl --url=http://${lh_external_ip}/v1 get volume | grep ${node} | wc -l)

  while [[ ${volume_count} -gt 0 ]]; do
    echo "waiting for volumes (${volume_count}) to detach from node: ${node}"
    local volume_count=$(retry lhctl --url=http://${lh_external_ip}/v1 get volume | grep ${node} | wc -l)
    sleep 1;
  done;

  echo "No volumes attached to ${node}"
}

cycle_nodes() {
  local role=$1

  local lh_external_ip=$(retry kubectl --context="${kube_context}" --namespace="${storage_ns}" get svc | grep longhorn-frontend | awk '{print $4}')

  # - drain and reboot nodes (sequentially)
  local nodes=$(retry kubectl --context="${kube_context}" get nodes -l role="${role}",retiring="${retire_time}" -o json |\
    jq -r '.items[].metadata.name')
  for node in ${nodes}; do
    drain_node ${node}
    check_node_volumes_are_detached ${node} ${lh_external_ip}
    reboot_node ${node}
    wait_for_ready_node ${node}
    delete_retirement_label ${node}
  done
}

# Checks whether all volumes have replicas that live outside the given node. IF not halts and logs until the condition is met
check_node_volumes_have_sufficient_replicas() {

  echo "Verifying sufficient replicas before rebooting node ${node}"

  local node=$1
  local lh_external_ip=$2

  local volumes=$(retry lhctl --url=http://${lh_external_ip}/v1 get volume | tail -n +3 | awk '{print $1}')

  for volume in ${volumes}; do
    rep_outside_node=$(retry lhctl --url=http://${lh_external_ip}/v1 get replica --volume=${volume} | grep -v ${node} | grep 'RW' | grep 'true' | wc -l)
    while [[ ${rep_outside_node} -eq 0 ]]; do
      echo "No running replicas of: ${volume} found outside node ${node}"
      sleep 15
      rep_outside_node=$(retry lhctl --url=http://${lh_external_ip}/v1 get replica --volume=${volume} | grep -v ${node} | grep 'RW' | grep 'true' | wc -l) 
    done;
  done;

  echo "All volumes have replicas outside ${node}"
}

drain_storage_node() {

  echo "Draining replicas from node: ${node}"

  local node=$1
  local lh_external_ip=$2

  replicas=$(retry lhctl --url=http://${lh_external_ip}/v1 get replica | grep ${node} | awk '{print $1}')
  for replica in ${replicas}; do
    retry lhctl --url=http://${lh_external_ip}/v1 delete replica ${replica}
  done
}

wait_for_lh_node_ready() {

  local node=$1
  local lh_external_ip=$2

  local node_ready=$(retry lhctl --url=http://${lh_external_ip}/v1 get node | grep ${node} | awk '{print $5}')
  while [[ ${node_ready} != "True" ]]; do
    echo "Waiting for longhorn to mark node: ${node} as Ready"
    sleep 10
    node_ready=$(retry lhctl --url=http://${lh_external_ip}/v1 get node | grep ${node} | awk '{print $5}')
  done;

  local node_schedulable=$(retry lhctl --url=http://${lh_external_ip}/v1 get node | grep ${node} | awk '{print $3}')
  while [[ ${node_schedulable} != "true" ]]; do
    echo "Waiting for longhorn to mark node: ${node} as Schedulable"
    sleep 15
    node_schedulable=$(retry lhctl --url=http://${lh_external_ip}/v1 get node | grep ${node} | awk '{print $3}')
  done;

}

cycle_storage_nodes() {

  local role=$1
  local ret_time=$2

  local lh_external_ip=$(retry kubectl --context="${kube_context}" --namespace="${storage_ns}" get svc | grep longhorn-frontend | awk '{print $4}')

  local nodes=$(retry kubectl --context="${kube_context}" get nodes -l role="${role}",retiring="${ret_time}" -o json |\
    jq -r '.items[].metadata.name')

  for node in ${nodes}; do
    check_node_volumes_have_sufficient_replicas ${node} ${lh_external_ip}
    drain_storage_node ${node} ${lh_external_ip}
    reboot_node ${node}
    wait_for_ready_node ${node}
    delete_retirement_label ${node}
    wait_for_lh_node_ready ${node} ${lh_external_ip}
  done

}

update() {
  local role=$1
  label_for_cycling ${role}
  cycle_nodes ${role}
}

resume() {
  local role=$1

  local target_nodes=$(retry kubectl --context="${kube_context}" get nodes -l role="${role}",retiring="${resume}" -o json |\
    jq -r '.items[].metadata.name')
  for target_node in ${target_nodes}; do
    drain_node ${target_node}
    reboot_node ${target_node}
    wait_for_ready_node ${target_node}
    delete_retirement_label ${target_node}
  done

}

echo "kube cluster: ${kube_context}"

if [[ "${role}" == "master" || "${role}" == "worker" ]]; then
  if [[ -n "${resume}" ]]; then
    resume ${role}
    exit 0
  fi

  update ${role}
fi

if  [[ "${role}" == "storage-node" ]]; then

  if [[ -z ${resume} ]]; then
    label_for_cycling ${role}
    cycle_storage_nodes ${role} ${retire_time}
  else
    cycle_storage_nodes ${role} ${resume}
  fi

fi

echo "run: result=\"success\""

